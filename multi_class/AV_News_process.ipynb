{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from json import JSONDecoder\n",
    "from functools import partial\n",
    "import json\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def json_parse(fileobj, decoder=JSONDecoder(), buffersize=2048):\n",
    "#     buffer = ''\n",
    "#     for chunk in iter(partial(fileobj.read, buffersize), ''):\n",
    "#         buffer += chunk\n",
    "#         while buffer:\n",
    "#             try:\n",
    "#                 result, index = decoder.raw_decode(buffer)\n",
    "#                 yield result\n",
    "#                 buffer = buffer[index:]\n",
    "#             except ValueError:\n",
    "#                 # Not enough data to decode, read more\n",
    "#                 break\n",
    "                \n",
    "# filename = '../datasets/av-news/first_av_crash.json'\n",
    "\n",
    "# # for loading the data if saved in a list, not memory efficient\n",
    "# # with open(filename, 'r') as content:\n",
    "# #     data = json.load(content)\n",
    "# # data = data[0]\n",
    "\n",
    "# # more memory efficient if not saved in a list\n",
    "# with open(filename, 'r') as content:\n",
    "#     for data in json_parse(content):\n",
    "#         break\n",
    "\n",
    "# Save the relevant attributes in a table format\n",
    "# def saveAsTable(data):\n",
    "#     results = []\n",
    "#     for key, value in data.items():\n",
    "#         tweetid = key\n",
    "#         tweet = value[0]\n",
    "#         author = value[1]\n",
    "#         user_dest = value[2]\n",
    "#         date = value[3]\n",
    "#         depth = value[4].split(' = ')[1]\n",
    "#         parent_tweetid = value[5]\n",
    "        \n",
    "#         result = [tweet, tweetid, date, depth, author, user_dest, parent_tweetid]\n",
    "#         results.append(result)\n",
    "        \n",
    "#     results = pd.DataFrame(results, columns=['Tweet', 'TweetID', 'Date', 'Depth', 'Author', 'UserDest', 'ParentID']) \n",
    "#     return results\n",
    "\n",
    "# dataTable = saveAsTable(data)\n",
    "# dataTable.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_vectors(tweets, model):\n",
    "    # dataset should be a pandas dataframe\n",
    "    dimension = 300\n",
    "    data_array = np.empty(shape=[0, dimension])\n",
    "    indexes = []\n",
    "    \n",
    "    for i, tweet in enumerate(tweets):\n",
    "        words = tweet.split()\n",
    "        if len(words) !=0:\n",
    "            feature = 0\n",
    "            for word in words:\n",
    "                try:\n",
    "                    feature += model[word]\n",
    "                except:\n",
    "                    pass\n",
    "            feature /= len(words)\n",
    "            try:\n",
    "                if feature.size == dimension:  \n",
    "                    data_array = np.append(data_array, [feature], axis=0)\n",
    "                    indexes.append(i)\n",
    "            except:\n",
    "                continue\n",
    "    indexes = np.asarray(indexes)\n",
    "    assert indexes.size == data_array.shape[0]\n",
    "    return data_array, indexes\n",
    "\n",
    "def remove_indices(weak_signals):\n",
    "    # remove indexes of tweets that do not have coverage\n",
    "    indices = np.where(np.sum(weak_signals, axis=1) == -weak_signals.shape[1])[0]\n",
    "    weak_signals = np.delete(weak_signals, indices, axis=0)\n",
    "    \n",
    "    return weak_signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../datasets/glove.42B.300d.txt', sep=\" \", quoting=3, header=None, index_col=0)\n",
    "glove_model = {key: val.values for key, val in df.T.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "      <th>receiver</th>\n",
       "      <th>date</th>\n",
       "      <th>depth</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>tokens</th>\n",
       "      <th>token_no_stop</th>\n",
       "      <th>...</th>\n",
       "      <th>topic_49</th>\n",
       "      <th>topic_50</th>\n",
       "      <th>topic_51</th>\n",
       "      <th>topic_52</th>\n",
       "      <th>topic_53</th>\n",
       "      <th>topic_54</th>\n",
       "      <th>topic_55</th>\n",
       "      <th>topic_56</th>\n",
       "      <th>topic_57</th>\n",
       "      <th>topic_assigned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>893846105959661568</td>\n",
       "      <td>@WHands80 why did this move? 29th Street pic.t...</td>\n",
       "      <td>whands80</td>\n",
       "      <td>sharrowsdc</td>\n",
       "      <td>2017-08-05 10:48:13</td>\n",
       "      <td>0</td>\n",
       "      <td>89384610595966156</td>\n",
       "      <td>why did this move th street</td>\n",
       "      <td>move th street</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003750</td>\n",
       "      <td>0.003743</td>\n",
       "      <td>0.001601</td>\n",
       "      <td>0.002335</td>\n",
       "      <td>0.003421</td>\n",
       "      <td>0.001901</td>\n",
       "      <td>0.012416</td>\n",
       "      <td>0.012451</td>\n",
       "      <td>0.001141</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>58</td>\n",
       "      <td>888069376687169537</td>\n",
       "      <td>I think one challenge would be depth - its rea...</td>\n",
       "      <td>whands80</td>\n",
       "      <td>bilsko</td>\n",
       "      <td>2017-07-20 12:13:33</td>\n",
       "      <td>0</td>\n",
       "      <td>88785776178194022</td>\n",
       "      <td>think one challenge would be depth its really ...</td>\n",
       "      <td>think challenge would depth shallow many stret...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001555</td>\n",
       "      <td>0.001552</td>\n",
       "      <td>0.000664</td>\n",
       "      <td>0.000968</td>\n",
       "      <td>0.001418</td>\n",
       "      <td>0.000788</td>\n",
       "      <td>0.005148</td>\n",
       "      <td>0.005162</td>\n",
       "      <td>0.000473</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>67</td>\n",
       "      <td>893935836781305856</td>\n",
       "      <td>The problem will be when an autonomous car is ...</td>\n",
       "      <td>doug_macintyre</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-08-05 16:44:46</td>\n",
       "      <td>seed</td>\n",
       "      <td>89392287313952768</td>\n",
       "      <td>the problem will be when an autonomous car is ...</td>\n",
       "      <td>problem autonomous car accident kill</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002198</td>\n",
       "      <td>0.002194</td>\n",
       "      <td>0.000938</td>\n",
       "      <td>0.001369</td>\n",
       "      <td>0.002005</td>\n",
       "      <td>0.001114</td>\n",
       "      <td>0.007278</td>\n",
       "      <td>0.007299</td>\n",
       "      <td>0.000669</td>\n",
       "      <td>47.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>75</td>\n",
       "      <td>893465217027461120</td>\n",
       "      <td>Humans cause most self-driving car accidents  ...</td>\n",
       "      <td>valevehiclemove</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-08-04 09:34:42</td>\n",
       "      <td>seed</td>\n",
       "      <td>89346521702746112</td>\n",
       "      <td>humans cause most self driving car accidents</td>\n",
       "      <td>human cause self driving car accident</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002772</td>\n",
       "      <td>0.002767</td>\n",
       "      <td>0.001183</td>\n",
       "      <td>0.001726</td>\n",
       "      <td>0.002528</td>\n",
       "      <td>0.001405</td>\n",
       "      <td>0.009177</td>\n",
       "      <td>0.009203</td>\n",
       "      <td>0.000844</td>\n",
       "      <td>47.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>77</td>\n",
       "      <td>892677727479902209</td>\n",
       "      <td>Why Pittsburgh Is Still The Center Of Self-Dri...</td>\n",
       "      <td>valevehiclemove</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-08-02 05:25:30</td>\n",
       "      <td>seed</td>\n",
       "      <td>89267772747990220</td>\n",
       "      <td>why pittsburgh is still the center of self dri...</td>\n",
       "      <td>pittsburgh center self driving car technology</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002198</td>\n",
       "      <td>0.002194</td>\n",
       "      <td>0.000938</td>\n",
       "      <td>0.001369</td>\n",
       "      <td>0.002005</td>\n",
       "      <td>0.001114</td>\n",
       "      <td>0.007278</td>\n",
       "      <td>0.007299</td>\n",
       "      <td>0.000669</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 74 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index            tweet_id  \\\n",
       "0      2  893846105959661568   \n",
       "1     58  888069376687169537   \n",
       "2     67  893935836781305856   \n",
       "3     75  893465217027461120   \n",
       "4     77  892677727479902209   \n",
       "\n",
       "                                                text           author  \\\n",
       "0  @WHands80 why did this move? 29th Street pic.t...         whands80   \n",
       "1  I think one challenge would be depth - its rea...         whands80   \n",
       "2  The problem will be when an autonomous car is ...   doug_macintyre   \n",
       "3  Humans cause most self-driving car accidents  ...  valevehiclemove   \n",
       "4  Why Pittsburgh Is Still The Center Of Self-Dri...  valevehiclemove   \n",
       "\n",
       "     receiver                 date  depth          parent_id  \\\n",
       "0  sharrowsdc  2017-08-05 10:48:13      0  89384610595966156   \n",
       "1      bilsko  2017-07-20 12:13:33      0  88785776178194022   \n",
       "2         NaN  2017-08-05 16:44:46   seed  89392287313952768   \n",
       "3         NaN  2017-08-04 09:34:42   seed  89346521702746112   \n",
       "4         NaN  2017-08-02 05:25:30   seed  89267772747990220   \n",
       "\n",
       "                                              tokens  \\\n",
       "0                        why did this move th street   \n",
       "1  think one challenge would be depth its really ...   \n",
       "2  the problem will be when an autonomous car is ...   \n",
       "3       humans cause most self driving car accidents   \n",
       "4  why pittsburgh is still the center of self dri...   \n",
       "\n",
       "                                       token_no_stop  ...  topic_49  topic_50  \\\n",
       "0                                     move th street  ...  0.003750  0.003743   \n",
       "1  think challenge would depth shallow many stret...  ...  0.001555  0.001552   \n",
       "2               problem autonomous car accident kill  ...  0.002198  0.002194   \n",
       "3              human cause self driving car accident  ...  0.002772  0.002767   \n",
       "4      pittsburgh center self driving car technology  ...  0.002198  0.002194   \n",
       "\n",
       "   topic_51  topic_52  topic_53  topic_54  topic_55  topic_56  topic_57  \\\n",
       "0  0.001601  0.002335  0.003421  0.001901  0.012416  0.012451  0.001141   \n",
       "1  0.000664  0.000968  0.001418  0.000788  0.005148  0.005162  0.000473   \n",
       "2  0.000938  0.001369  0.002005  0.001114  0.007278  0.007299  0.000669   \n",
       "3  0.001183  0.001726  0.002528  0.001405  0.009177  0.009203  0.000844   \n",
       "4  0.000938  0.001369  0.002005  0.001114  0.007278  0.007299  0.000669   \n",
       "\n",
       "   topic_assigned  \n",
       "0            40.0  \n",
       "1            42.0  \n",
       "2            47.0  \n",
       "3            47.0  \n",
       "4            19.0  \n",
       "\n",
       "[5 rows x 74 columns]"
      ]
     },
     "execution_count": 416,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create test data for the av_news data. Run once\n",
    "file = 'world_first_l3'\n",
    "filename = '../datasets/av-news/'+file+'/'\n",
    "\n",
    "df = pd.read_csv(filename+file+'.csv')\n",
    "np.random.seed(2000)\n",
    "\n",
    "# set up training and test data\n",
    "num_test = int(0.1*df.shape[0]) if int(0.1*df.shape[0]) < 200 else 200\n",
    "test_indexes = np.random.choice(df.shape[0],num_test,replace=False)\n",
    "indexes = np.arange(df.shape[0])\n",
    "indexes = np.delete(indexes, test_indexes)\n",
    "\n",
    "# get dev set\n",
    "np.random.seed(2000)\n",
    "dev_set = np.random.choice(indexes, 50, replace=False)\n",
    "indexes = np.delete(indexes, [np.where(indexes == i)[0][0] for i in dev_set])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2169, (1919, 300))"
      ]
     },
     "execution_count": 417,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = df.token_no_stop.values\n",
    "tweet_vectors, tweet_index = get_text_vectors(tweets[indexes], glove_model)\n",
    "dev_vectors, dev_index = get_text_vectors(tweets[dev_set], glove_model)\n",
    "test_vectors, test_index = get_text_vectors(tweets[test_indexes], glove_model)\n",
    "assert dev_index.size == dev_set.size\n",
    "tweets.size,tweet_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save av_news dev data\n",
    "np.save(filename+'dev_features.npy', dev_vectors)\n",
    "\n",
    "# save av_news test data\n",
    "np.save(filename+'test_features.npy', test_vectors)\n",
    "# np.savetxt(filename+\"test_data.csv\", tweets[test_indexes], delimiter=\",\",fmt='%s')\n",
    "# np.savetxt(filename+\"dev_set.csv\", tweets[dev_set], delimiter=\",\",fmt='%s')\n",
    "\n",
    "# save av_news data\n",
    "np.save(filename+'data_features.npy', tweet_vectors)\n",
    "\n",
    "# # incase I mistakenly resave the test tweets\n",
    "# # labels = np.load(filename+'test_labels.npy')\n",
    "# # num_test = np.vstack([tweets[test_indexes],labels]).T\n",
    "# # np.savetxt(filename+\"test_data.csv\", num_test, delimiter=\",\",fmt='%s')\n",
    "tweets = tweets[indexes]\n",
    "tweets = tweets[tweet_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and save data labels\n",
    "test = pd.read_csv(filename+'test_data.csv')\n",
    "np.save(filename+'test_labels.npy', test.labels.values)\n",
    "\n",
    "test = pd.read_csv(filename+'dev_set.csv')\n",
    "np.save(filename+'dev_labels.npy', test.labels.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find url in tweets\n",
    "def urlInTweet(raw_texts):\n",
    "    weak_signal = []\n",
    "    for tweet in raw_texts:\n",
    "        urls = re.findall('(?:(?:https?|ftp):\\/\\/)?[\\w/\\-?=%.]+\\.[\\w/\\-?=%.]+', tweet)\n",
    "        x = 1 if len(urls) > 0 else 0\n",
    "        weak_signal.append(x)\n",
    "    return weak_signal\n",
    "\n",
    "test=df.text.values[indexes]\n",
    "url_signal = urlInTweet(test[tweet_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy import spatial\n",
    "# # keyword weak_signal\n",
    "# keywords = ['self','autonomous','crash']\n",
    "# keywords_vec = [glove_model[key] for key in keywords]\n",
    "# keywords_vec = np.mean(keywords_vec)\n",
    "# keyword_signal = [1 - spatial.distance.cosine(vec, keywords_vec) for vec in tweet_vectors] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define cluster signals\n",
    "from sklearn.cluster import KMeans\n",
    "kmeans = KMeans(n_clusters=10, init='k-means++').fit(tweet_vectors)\n",
    "cluster_signals = np.ones(tweets.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['indifferent mainstream tesla weakest spot exterior design',\n",
       "       'morality question fascinating autonomous car hit jaywalker swerve endanger driver',\n",
       "       'scared killed jaywalking pedestrian',\n",
       "       'grrrr glad hurt injured driver slow check switch riding dwn boylston bbay regular event',\n",
       "       'blame pissed put blame delta insult passenger',\n",
       "       'crash tesla promoted autopilot china zi dong jia shi meaning car drive',\n",
       "       'elon musk experienced zuckerberg autopilot car killed person scary regulated',\n",
       "       'gostei de um autopilot predicts car crash happen',\n",
       "       'elon interior shared noticed', 'think government study elon musk',\n",
       "       'perjurous gnome job',\n",
       "       'uber degrades city professionalism driving occupation',\n",
       "       'room cross almighty mercy endures',\n",
       "       'fact joy used demetrius shipp pac interesting',\n",
       "       'trying virgin airline shitcarts road',\n",
       "       'problem automate retweets verbal orgasm',\n",
       "       'know way careless pedestrian mow kill poor defenseless turning motorist outrageous',\n",
       "       'ontario owen sound timmins',\n",
       "       'liable self driving car crash sorusunu duydugumda ben diye cevap vermemek icin zor tutuyorum',\n",
       "       'crock shit elon musk',\n",
       "       'could marry cortana ai got jealous siri cortana hack driverless car crash cortana affair hal',\n",
       "       'hahahahahaha arriva train wale',\n",
       "       'retweeted information fellow hgv driver factory trained merc benz diesel technician aware adblu',\n",
       "       'signal single singal', 'rest bloody road blackpool fylde',\n",
       "       'watched collision dash cam shocking', 'hshahah phat ai',\n",
       "       'watched driverless car hit motorcyclist th moto unusual liking future',\n",
       "       'remember smear campaign nikola tesla killed elephant',\n",
       "       'hilarious wks last equity raise reported fatality yr tsla',\n",
       "       'tesla stock accident waiting happen say shah gilani',\n",
       "       'shame uber lyft',\n",
       "       'tesla inventory accident ready occur say shah gilani',\n",
       "       'robot know clinton punchline',\n",
       "       'subscribe elon musk news curated article analysis',\n",
       "       'musk zuck killed ai test robot started ripping tesla fb owner ouche day ag bay',\n",
       "       'command spaceship fleet dreadnought open beta',\n",
       "       'come shared av worried barf bart',\n",
       "       'luck event imminent collision miata slip tundra chassis',\n",
       "       'odyssey tailgate calling',\n",
       "       'ipad stapled lada inspired dash killed interest model',\n",
       "       'wearing frog outfit', 'musk try escape',\n",
       "       'king road autonomous room auto chip grotto trunked',\n",
       "       'seems ike thomas traini truck engine',\n",
       "       'stop others beast human pure explotation',\n",
       "       'lowe debelle mit phd pedigree would expect lowe back debelles dovishness last friday cpi',\n",
       "       'elon musk said tesla may delay cross country road trip self driving car tsla danielle muoio',\n",
       "       'elon musk said tesla may delay cross country road trip self driving car tsla danielle muoio feedburner',\n",
       "       'thatvcould mean tesla others', 'shrill manly tenor',\n",
       "       'srecan rodjendan dositeju',\n",
       "       'oil company killed ev stop tesla see opec lyric song wish tesla pantha',\n",
       "       'omg watched tesla predicts crash compilation left speechless',\n",
       "       'test food make certain tampered cmon vlad shared playbook',\n",
       "       'fault racist head moron blame parent',\n",
       "       'elon musk got geek hooked',\n",
       "       'want squashed grape volvo crash faster tesla guy snug volvo guy dead',\n",
       "       'sure taken pokeballs night edc accident green tesla fineeee lolol',\n",
       "       'herkes tesla alabilene kadar killed electric car',\n",
       "       'age thought reince priebus newest car look priebus failed crash test rating',\n",
       "       'attempt strike pose camera resulted month hip dysplasia',\n",
       "       'speedy speed pas ahhhhhhhh creepiness',\n",
       "       'wierd cause evo horrible car mirage',\n",
       "       'plant abwarten tee trinken',\n",
       "       'oplettende tesla bestuurder voorkomt crash',\n",
       "       'aldolfo dominguez tesla tom ford mont blanc spirit glass door professa crash course stanford',\n",
       "       'saw tweet ditto pb said',\n",
       "       'sasquach radio killed duluth gooseberry fall nirvana tesla',\n",
       "       'oldie goodie elon musk space dream killed tesla',\n",
       "       'tried human scraped mudguard', 'saw described mamil highway',\n",
       "       'mood minnesota twin team trade garcia kintzler',\n",
       "       'hip hop lizzo minnesota lizzo',\n",
       "       'streaming insanity mt teenage driver livestreams deadly crash',\n",
       "       'gm wil weer geen ev verkopen killed electric car part time work thanks',\n",
       "       'part bestaat sind heet revenge electric car docu kijkplezier',\n",
       "       'lunatic guy bannon going killed fundamentalist fundamentalist',\n",
       "       'call lesta owner change name elio musk money come',\n",
       "       'look angry catfish aftermarket potential whisker add ons',\n",
       "       'nauto raise fuel expansion autonomous techcrunch',\n",
       "       'neymar bought worried',\n",
       "       'stick fact driver say deactivated autopilot crash seine mail seht ihr',\n",
       "       'zombie aboutcalling whatthey disrespectful pedestrian asthere disrespectful driver cyclist endanger life',\n",
       "       'waiting yh due',\n",
       "       'elon musk bipolar suffers unrelenting stress reveal honest tweet',\n",
       "       'halt thaad deployment overthrow kidnap disappear cancel fat fingered mao noko',\n",
       "       'lady tecniq news kotaku anime jalopnik driver marsh crash say fault',\n",
       "       'elon musk inspired industry hyperloop startup building',\n",
       "       'vraiment vite blocage',\n",
       "       'saying elon musk smart weight given opinion press disproportional intelligence',\n",
       "       'oligarch killed birdy', 'could forseen result',\n",
       "       'niet oorzaak van tesla crash gelezen',\n",
       "       'admit gave musk verbal approval',\n",
       "       'focus semi truck full illegals sneak prey kill kid ford taxd',\n",
       "       'dow spx selloff', 'predict swift demise lyft',\n",
       "       'seeing tesla continue profitless elon push much',\n",
       "       'strong barrier wti',\n",
       "       'mention passable pour la tesla model lors de son dernier crash test',\n",
       "       'hit run accident mt morris rd bray caller white chevy cruise hit white car dmx bray',\n",
       "       'narf narf narf narf',\n",
       "       'ctricot cognitive mobility olli self driving vehicle watson cogn',\n",
       "       'change vibe ride gestapo laconic',\n",
       "       'git dockerfile cloud testing deployment',\n",
       "       'used say lancashire first spaker stink maker',\n",
       "       'elaborate become entangled quagmire confusion',\n",
       "       'self driving car increase car ownership sempre falo isso ngm ouve',\n",
       "       'lollz ydae dae na dey lagos road ni shld drive car road pm',\n",
       "       'prometheus project driverless car using saccardic vision european stupidity mothballed waste',\n",
       "       'legal look elon musk plan colonize mar thespacereview',\n",
       "       'drive solution sucesss',\n",
       "       'mouth breather know parent boy scout prius driver margin error',\n",
       "       'look barley scalp',\n",
       "       'hawk sittin middle road tried shooing decided fly car driving oops',\n",
       "       'us marie gomez ram darpa', 'novelist proposes adjunct darpa',\n",
       "       'car turned soweto riverlea',\n",
       "       'accident soweto highway boysens coming joburg motorist may use alternative road',\n",
       "       'pocket sized protestors',\n",
       "       'check goddamn source croud group pedestrian crossing road',\n",
       "       'pillion mine matey singe seat cafe racer mrsrtj head passenger car mind tapping lid',\n",
       "       'mother project moonshot', 'fozzie bear drive',\n",
       "       'apollo creed schwarzenegger', 'duits international die gast',\n",
       "       'faster mine got gigapower',\n",
       "       'package seattle apologize confusion caused el',\n",
       "       'remember kat mapitsi history', 'joy rapture woohoo',\n",
       "       'abaratir periferia corones tarifaries dedicar euro compensacions autopistes poc peatges lombra reduir accident',\n",
       "       'honda dear brother', 'africa baddest hit anoda',\n",
       "       'oops forgot tell rejiggering beat', 'avis teaming waymo program',\n",
       "       'girl control handcuff',\n",
       "       'young consent sterilisation heartbreak city',\n",
       "       'read goat wearing warranted theft',\n",
       "       'fault loss life self driving car ownr pssgr automkr jaywlkr',\n",
       "       'perplexing uber mangle relationship important asset driver',\n",
       "       'heinz history center mr rogers pittsburgh',\n",
       "       'hit find english sub mamoru oshii',\n",
       "       'spacesuit go may rag ready relic', 'preview ebit margin seen'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fi_av [0,6,8],uni_mich [1,5,6],goo_lex [1,6,8],int_tesla [0,3,7],mcity_shu [0,1,6,8],tes_feb [0,1,2,4,5,8],wor_l3 [0,3,4]\n",
    "negative_samples = [0,3,4] # change this as you investigate the data\n",
    "tweets[kmeans.labels_==4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "for num in negative_samples:\n",
    "    cluster_signals[cluster_signals==num] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define weak signals for seed tweets and topic signals\n",
    "seed_signals=df.depth.values[indexes]\n",
    "seed_signals=1*(seed_signals[tweet_index] ==' seed')\n",
    "\n",
    "# first av crash, change the topics for a different dataset\n",
    "av_topics = []\n",
    "for line in open(filename+file+'.txt'):\n",
    "    lines = line.split(' ')\n",
    "    if 'AV' in lines[1]:\n",
    "        av_topics.append(lines[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add up the topics to get topic weak signal\n",
    "col_name='topic_'\n",
    "topic_signal = np.zeros(tweet_vectors.shape[0])\n",
    "for num in av_topics:\n",
    "    topic = df[col_name+num][indexes].values\n",
    "    topic_signal = np.add(topic_signal, topic[tweet_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1919, 4)"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# join the seed and topic signals\n",
    "weak_signals = np.stack([seed_signals, topic_signal, url_signal, cluster_signals], axis=1)\n",
    "weak_signals.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the av news weak signals\n",
    "np.save(filename+'weak_signals.npy', weak_signals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_results(filename):\n",
    "    with open(filename, 'r') as content:\n",
    "        data = json.load(content)\n",
    "    return data\n",
    "\n",
    "# read from the train data\n",
    "all_signal_results = load_results('results/av_news/crash_results.json')\n",
    "# # load indexes of original data Table\n",
    "# data_indexes = np.load('../datasets/av-news/indexes.npy')\n",
    "\n",
    "# Get predictions of the models\n",
    "train_indexes = np.ravel(all_signal_results['Adversarial model']['train_indexes'])\n",
    "train_pred = np.ravel(all_signal_results['Adversarial model']['train_predictions'])\n",
    "majority_vote = np.ravel(all_signal_results['Weak model']['baseline_train_predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I only care about the positive predictions from the models\n",
    "train_onespred = train_indexes[train_pred==1.0]\n",
    "majority_onespred = train_indexes[majority_vote==1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample 100 predictions to manually evaluate\n",
    "indexes = np.random.choice(train_onespred, 100, replace=False)\n",
    "#sample 100 predictions from majority vote\n",
    "majority_indexes = np.random.choice(majority_onespred, 100, replace=False)\n",
    "\n",
    "# Create a Pandas Excel writer using XlsxWriter as the engine.\n",
    "writer = pd.ExcelWriter('results/av_news/sample_pred.xlsx', engine='xlsxwriter')\n",
    "df.tokens[indexes].to_excel(writer, sheet_name = 'rcl_pred')\n",
    "df.tokens[majority_indexes].to_excel(writer, sheet_name = 'majority_pred')\n",
    "random_sample = np.random.choice(train_indexes, 100, replace=False)\n",
    "df.tokens[random_sample].to_excel(writer, sheet_name = 'random')\n",
    "writer.save()\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array(['driver in nj claims that his tesla was in autopilot mode and would not let him take control of the steering wheel to avoid an accident',\n",
      "       'you might be able to kill some off but do not know how you would change it without medical intervention',\n",
      "       'waymo cruise apple and other autonomous vehicle makers reveal their driving',\n",
      "       'drop in sales in jan was expected usual slow month for industry rush to buy in dec for tax credit production diverted to europe china for jan feb agree we will see where demand levels off but definitely not panicking over usually slow month',\n",
      "       'ai is our future just whose ai love it refer to myself as ai because it is slightly better than fairing princess',\n",
      "       'think it is just hong kong that does it as it is based around the mountain there',\n",
      "       'impossible now thanks to drive by wire not impossible when it was simple mechanical system our bmw series back in the day stuck at mph on the motorway the dealership said we imagined it but when it was investigated they found dirt had got in the system very scary',\n",
      "       'am gonna hit myself with my car me how will you hit yourself with your own car madison cruise control babyyyy',\n",
      "       'it does not say you are limited to one cockroach',\n",
      "       'put strike price is my limit order for the week sell them',\n",
      "       'how do you explain guidance for model at fremont by the end of',\n",
      "       'any guess on price kia will also have plenty of credits if something doesnt change before then',\n",
      "       'claim blames ducey state for uber self driving crash that killed woman via',\n",
      "       'thanks john was bit lazy and did not do monthly summaries for december or january',\n",
      "       'if it tries again on monday and fails it could sell off to fill the gap up',\n",
      "       'bev sales up holy cow looks like the building of their dreams is well under way way to go',\n",
      "       'turbulent offseason continues with car accident that damaged his',\n",
      "       'it will not be march th think about it months notice was over months notice lucky if it is unveiled at the end of march',\n",
      "       'teaching self driving car to predict pedestrian movements',\n",
      "       'do not confuse commitment to pay with actual payment the commitment helps keep the growth story alive maybe they will erect another state of the art assembly tent to try to bypass chinese tariffs likely they are bankrupt in another or two so total outlay in minimal',\n",
      "       'no need to ban diesel the tech is available',\n",
      "       'this is an older tesla model pre this car is either trade in or privately owned vehicle not new inventory',\n",
      "       'when tsla goes bk tslaq peeps will be like',\n",
      "       'tslaq scoop tsla sticks to promised timeline thus bankwupcy must be imminent',\n",
      "       'we cannot blame them also that hat scarf combo is amazing',\n",
      "       'model stops itself to avoid potentially disastrous accident tesla new motto should be we have better co pilots than angels',\n",
      "       'toyotas moonshot self driving car for sale in year automotive news europe via',\n",
      "       'tesla model crash test forcinducts video picks business insider crash test videos national geographic tesla tesla crash test videos tesla crash testing tesla model video picks',\n",
      "       'info destination ditch tesla driver blames autopilot for new jersey crash updated',\n",
      "       'secretive self driving car project starting to come into focus the verge',\n",
      "       'apple has had to lay off employees from their self driving car project',\n",
      "       'no wonder is accused of being bribed and being soft on elon tsla etc tsla hello',\n",
      "       'think to is reasonable target considering inflation with lopsided demand for premium vehicles still exceeding production in europe and asia tesla does not want people waiting for the cheap version when they try to drain inventory in the us in march for ec',\n",
      "       'yes these things are over down here we have gst and luxury car tax too which kicks in above model conveniently still listed as us which will not include the gst even',\n",
      "       'the state of self driving car laws across the brookings institution via',\n",
      "       'digging into self driving data and more car news this week plus we bid adieu to the airbus amazon makes move and we take tour of the gear that keeps nascar racers on the oval',\n",
      "       'there are deliveries scheduled for next week for belguim or netherlands think they will do that partially for later ships though',\n",
      "       'early mid march would drain us inventory and production enabling them to delay overseas production until no cars on ships free cash flow when it counts question then is how does lease accounting affect the quarterly report in that case',\n",
      "       'creating self driving vehicles was the task for computer science students today students created their own coding programs to make their self driving car maneuver the west halls the students had to determine the logistics of the course program test make adjustments',\n",
      "       'most welcome keep supporting',\n",
      "       'shorting is also about timing the tslaq window is closing superficially tsla has all the makings of risk but there is its is special company it would be interesting to bet which ice oems would be around in five years',\n",
      "       'there are cars in parking lots',\n",
      "       'there are definitely some ex tesla owners among the ipace owners it is not only jag fanbase problem leasing rates are very unattractive low resale value jag does not have financing arm',\n",
      "       'it is non optimal lr pack does having lower cost separate battery for sr offset the complexity of the supply chain from having three different batteries sr mr and lr from the recent and argue it does not',\n",
      "       'sorry cannot help you there not into fanfic',\n",
      "       'daily prizes have been dropped off',\n",
      "       'short dxy is not contrarian view at all right now think the critique is towards gs research in general than against the short dxy thesis',\n",
      "       'waiting for the sixers game to start locked in for smoke detector awareness thank you',\n",
      "       'it helps that all four of those are not appliances and do not litter dealer lots for long',\n",
      "       'liberals give blackberry million to support self driving car development',\n",
      "       'and yet none of them can deliver specs or demand that come close to that of tsla hmm',\n",
      "       'disruption saves on repair',\n",
      "       'absolutely great am an modx owner had slight crash the bodyshop in vienna austria promisssed me loaner but thr loaner was crashed too hate to drive combuster now',\n",
      "       'again am not worried about tesla demand if you do not like the company short the stock do not like the car do not buy it you keep on and will keep enjoying my car deal',\n",
      "       'how can you tell the car automatically applied the brakes',\n",
      "       'amazon invests in startup building electric trucks and suvs the verge via',\n",
      "       'so you paid for these puts more than bucks usually have seen tslaq posting only penny trades but this is legit trade',\n",
      "       'would hope not also teslas is not unionized workforce',\n",
      "       'admit that did not dig deeper is there rate per model on the road',\n",
      "       'since my name is trevor as well will say have no idea we got used model over year ago',\n",
      "       'not at all first model is not sold very well because inventories are growing second even if it were selling very well my sentence would not imply it will be successful model because my sentence has the opposite order implies which is not the same as implies',\n",
      "       'teslas latest update killed some vehicles autopilot',\n",
      "       'this probably would have made the news in other cars anyway very uncommon for an accident like this due to poor decisions in another car it probably would have resulted in fatality though',\n",
      "       'los angeles ca an agency hid tesla crash data for nearly two years is that any way to build trust in driverless cars',\n",
      "       'nhtsa claim that tesla autosteer reduced crashes proven bogus remember the nhtsa report that claimed tesla autopilot cut fatality rates by percent it was not true it was not even close to true the post nhtsa claim that tesla autosteer reduced crashes proven bogus appe',\n",
      "       'also lost in this is that people like driving to certain extent especially super fun tesla us humans animals will need to share road these robotic beasts we do some illogical stuff sometimes thus we want these lb beasts to learn via minimum amount of miles',\n",
      "       'there must be spitoon app surely its',\n",
      "       'no doubt uber wash their hands as their passengers sign their rights away yet uber were happy to tout car when it is not fit for purpose',\n",
      "       'all those motorcycle riders see with cameras on their helmets are looking to crash so they can blame the motorcycles manufacturer',\n",
      "       'teens burned to death after mph crash the lawsuit blames tesla for the speed and fire',\n",
      "       'we need to move people from vehicles crash stats to tesla autopilot to prevent crashes deaths deaths yr us roads ap crash event mm miles tesla without ap crash event mm miles us crash miles tslaq',\n",
      "       'is the first suv to receive perfect crash test rating teslas are vigorously designed to minimize chances of injury death in crash if you can afford tesla why would you drive anything else safety is so important tsla tslaq',\n",
      "       'office of defects investigation closed the preliminary evaluation saying they could find nothing wrong in fact the agencys examination of the crash data showed that teslas autopilot system beefed up with autosteer was god damned miracle exactly',\n",
      "       'oh jeeez wake up the is federal money for qnx to develop software for self driving car ford has got nothing to do with it',\n",
      "       'good but not new it is quite an usual business model for number of furniture sellers in india and many developing countries need to document this and assess how much is economies in developing countries confident that developed countries will be lagging far behind',\n",
      "       'we are buying only range rovers now',\n",
      "       'yet not one single person snapped this rare bigfoot sighting',\n",
      "       'would not you need an inflatable raft to cross the river',\n",
      "       'believers believe while naysayers dig in baillie gifford in uk now owns approx mm shares valued at',\n",
      "       'am always willing to go the extra mile but wouldnever risk my livelihood in this situation if anything were to happen or situation occurred the driver me is screwed am all for helping but any veteran driver in the situation was in would not have given this ride',\n",
      "       'tesla owner whose car crashed sunday evening in new jersey blamed the vehicles autopilot which he told police unexpectedly took over moments before the accident it was just after',\n",
      "       'can we expect teslas presence in pakistan anytime sooner',\n",
      "       'too big to fail blessed by pwc with no going concern notice and coming out earlier than in previous years may indicate raise attempt asap tsla needs to hurry but can they raise money before showing deliveries',\n",
      "       'thanks but leases are unattractive because the resale value is set pretty low',\n",
      "       'excellent get to see more made in china bs falling from the sky on fire in my lifetime makes my day',\n",
      "       'of course texting and driving is just as bad as drinking and driving',\n",
      "       'am buyer if they ever produce version',\n",
      "       'by your logic someone who ordered his car in jan is still waiting while some guy in the eu gets his car',\n",
      "       'seems like you were caught in lie and now are walking it back thanks you mean how jaguar tata is ipace hint they are not magna is',\n",
      "       'should airbags have deployed with this impact',\n",
      "       'it is altitude envelope is feet its never going go past mph in speed just read the instructions',\n",
      "       'are you that stup to know tsla',\n",
      "       'which makes software for vehicles cited reasons for disengagement error which meant vehicle would be uncertain of its location in data from different sensors on vehicle via',\n",
      "       'it is coming in roughly months see in the earnings call',\n",
      "       'model receives star rating in nhtsa crash tests',\n",
      "       'the self driving car that killed someone they put it right back in the same area smh you get what you get',\n",
      "       'three gm cars not trucks or commercial vehicles trying to remember when that was last the case in north america',\n",
      "       'we are looking forward to it honored to be part of your big apple getaway',\n",
      "       'well you know they do not really need brakes because the regen is so good',\n",
      "       'exactly there is sometimes divergence between book value and share price people will buy stock if they see growth potential in the future people who can see the impact of market shifting toward zero emissions will realise the potential of tesla to become the next vw'],\n",
      "      dtype=object)\n"
     ]
    }
   ],
   "source": [
    "# randomnly sample 100 tweets from the data\n",
    "pprint(df.tokens.values[random_sample])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
